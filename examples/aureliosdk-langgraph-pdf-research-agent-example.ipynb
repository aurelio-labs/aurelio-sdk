{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ðŸ“Œ **LangGraph** Custom Tool Calling\n",
    "\n",
    "In this notebook we will have a look at how to call pre-defined and custom-made tools within our LangGraph application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Setting Up OpenAI API Key\n",
    "\n",
    "Before we begin using LangGraph, you'll need to set up your `OpenAI API key`. This key is required for generating `responses` that power our LangGraph application.\n",
    "\n",
    "#### ðŸŒ Getting Your API Key\n",
    "\n",
    "1. Visit [OpenAI API Keys Page](https://platform.openai.com/api-keys)\n",
    "2. Sign in or create an account if you haven't already\n",
    "3. Click on \"Create new secret key\"\n",
    "\n",
    "> âš ï¸ **Note**: New users get `$5 in free credits`. After that, you'll need to set up billing to continue using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\n",
    "    \"Enter OPENAI_API_KEY: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model` is important to consider here, alot of the **local models struggle using tool calling**, however this is usually outlined on the model description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# The LLM model we want to use\n",
    "openai_model = \"gpt-4o-mini\"\n",
    "# For normal accurate responses\n",
    "llm = ChatOpenAI(temperature=0.0, model=openai_model, openai_api_key = os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Setting Up SerpAPI key\n",
    "\n",
    "To test both `custom` and `pre-defined` tools, we want to use `SerpAPI` as a search tool, in order to do this we need the API key.\n",
    "\n",
    "#### ðŸŒ Getting Your API Key\n",
    "\n",
    "1. Visit [SerpAPI Keys Page](https://serpapi.com/users/sign_in)\n",
    "2. Sign in or create an account if you haven't already\n",
    "3. Click on \"Create new secret key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\") or getpass(\n",
    "    \"Enter SERPAPI_API_KEY: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Setting Up Aurelio AI API key\n",
    "\n",
    "To obtain articles from the web\n",
    "\n",
    "#### ðŸŒ Getting Your API Key\n",
    "\n",
    "1. Visit [Aurelio Platform API Keys Page](https://serpapi.com/users/sign_in)\n",
    "2. Sign in or create an account if you haven't already\n",
    "3. Click on \"Create new secret key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "os.environ[\"AURELIO_API_KEY\"] = os.getenv(\"AURELIO_API_KEY\") or getpass(\n",
    "    \"Enter Aurelio API Key: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurelio_sdk import AurelioClient\n",
    "\n",
    "client = AurelioClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_key', 'base_url', 'chunk', 'embedding', 'extract_file', 'extract_url', 'get_document', 'headers', 'source', 'wait_for']\n"
     ]
    }
   ],
   "source": [
    "print(dir(client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key is valid.\n"
     ]
    }
   ],
   "source": [
    "test_url = \"https://arxiv.org/pdf/2408.15291\"\n",
    "try:\n",
    "    response = client.extract_url(url=test_url, quality=\"low\", chunk=True, wait=60, polling_interval=5)\n",
    "    print(\"API key is valid.\")\n",
    "except Exception as e:\n",
    "    print(f\"API key is invalid: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling our **Tools** ðŸ› ï¸\n",
    "We have two ways in this notebook you can attach tools:\n",
    "\n",
    "- If you want to attach a **pre-made** tool such as SerpAPI, LangChain comes with a few tools already defined within the `load_tools` function\n",
    "- If you would instead prefer to use **custom** tools we also define a handful of mathmatic operations which will also get passed into our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools([\"serpapi\"])\n",
    "\n",
    "serpapi_tool = tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurelio_sdk import ExtractResponse\n",
    "\n",
    "def obtain_pdf_from_url(pdf_url: str) -> str:\n",
    "    \"\"\"\n",
    "        Obtains the pdf from the pdf_url given, a properly formatted \n",
    "        one should look like: https://arxiv.org/pdf/2408.15291\n",
    "        make sure that the url given is a pdf format and not text/HTML\n",
    "    \"\"\"\n",
    "    response_pdf_url: ExtractResponse = client.extract_url(\n",
    "        url=pdf_url, quality=\"low\", chunk=True, wait=60, polling_interval=5\n",
    "    )\n",
    "\n",
    "    response_pdf_url\n",
    "    content = response_pdf_url.document.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_string(content: str) -> str:\n",
    "    \"\"\"\n",
    "        This function will summarize the content passed within, \n",
    "        the content must be in string formatting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = llm.invoke(f\"Please provide a concise summary of the following article:\\n\\n{content}\")\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating summary: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def create_slug(title):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    title = title.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "    # Replace spaces with hyphens\n",
    "    slug = title.replace(\" \", \"-\")\n",
    "    return slug\n",
    "\n",
    "def extract_title(content: str) -> str:\n",
    "    \"\"\"\n",
    "        This function will extract the title from the content passed within,\n",
    "        the content must be in string formatting.\n",
    "        the return will be created as a slug title\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = llm.invoke(f\"Extract the title from this article. Look at the first few lines as titles are usually at the top:\\n\\n{content[:500]}\")\n",
    "        return create_slug(response.content)\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting title: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags(content: str) -> list[str]:\n",
    "    \"\"\"\n",
    "        This function takes in the content as a string and outputs a bunch of tags\n",
    "        that best match the content given, the output is a list of strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = llm.invoke(f\"Based on the content, generate relevant tags. Return only a Python list of strings.\\n\\nContent: {content[:1000]}\")\n",
    "        # Convert the string response to an actual list\n",
    "        tags_string = response.content.strip()\n",
    "        # Remove any markdown formatting and evaluate the string as a Python list\n",
    "        tags_string = tags_string.replace('```python', '').replace('```', '')\n",
    "        tags = eval(tags_string)\n",
    "        return tags\n",
    "    except Exception as e:\n",
    "        return [f\"Error extracting tags: {str(e)}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we **bind** our tools using the `bind_tools` method which passes in a list of tools which we can create down below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'serpapi_tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\u001b[43mserpapi_tool\u001b[49m, obtain_pdf_from_url, summarize_string, extract_title]\n\u001b[0;32m      2\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind_tools(tools)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'serpapi_tool' is not defined"
     ]
    }
   ],
   "source": [
    "tools = [serpapi_tool, obtain_pdf_from_url, summarize_string, extract_title]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¦ Setting Up LangGraph\n",
    "\n",
    "Now we want to incorporate the `llm_with_tools` into our application, to do this, we will create an **assistant** node that will create tool calls and end the application if nessercary, then we create a **conditional edge** that will use the tool box we created previously, this all gets handled through the `MessageState` which sends AI messages with tool calls all included for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MessagesState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Graph\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m builder \u001b[38;5;241m=\u001b[39m StateGraph(\u001b[43mMessagesState\u001b[49m)\n\u001b[0;32m      8\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, assistant)\n\u001b[0;32m      9\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m, ToolNode(tools))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MessagesState' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª Testing the LangGraph\n",
    "\n",
    "Ensure that the `tools` are correctly routed to the user queries handlers, within this we can see:\n",
    "\n",
    "- User inital query under `Human Message`\n",
    "- Tool calls and args passed in under `Ai Message`\n",
    "- Tool usage under `Tool Message`\n",
    "- Once finished the `Ai Message` will have a final answer for the query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 11:39:04 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-05 11:39:07 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Find be an PDF article online about LangChain, obtain the pdf, and generate a list of tags using only tools.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
